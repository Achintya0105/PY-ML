{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fab1c60689787ab667ecb59be68d124c20072e59"
   },
   "source": [
    "# PARiS Classifier\n",
    "\n",
    "## Development Dataset\n",
    "\n",
    "Load the data and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "copyfile(src = \"../input/fairness.py\", dst = \"../working/fairness.py\")\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from fairness import read_skills\n",
    "\n",
    "SEED = 0\n",
    "WEIGHTS = pickle.load(open(\"../input/PARiS.pickle\", \"rb\"))\n",
    "all_skills = read_skills(\"../input/skills.txt\")\n",
    "target = \"Interview\"\n",
    "predictors = all_skills\n",
    "demographics = [\"Veteran\", \"Female\", \"URM\", \"Disability\"]\n",
    "data = pd.read_csv(\"../input/resumes_development.csv\", index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ec5d30a7ecccc6383366bc919d89b92a19b7e01b"
   },
   "source": [
    "View the correlations between demographic features and the target variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bebfe9863211ccce1271e02ef6c2679e0a05fe3"
   },
   "outputs": [],
   "source": [
    "data[[target] + demographics].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ba044e7e769a3483f3927cb6ac4397b26c7e557"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from fairness import PARiSClassifier, evaluate_model, rank_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1d90b65a77bceb5a0a194af0eb5d953fef87453f"
   },
   "outputs": [],
   "source": [
    "d_train, d_test = train_test_split(data, test_size=0.5, stratify=data[target], shuffle=True, random_state=SEED)\n",
    "X_train = d_train[predictors]\n",
    "y_train = d_train[target]\n",
    "X_test = d_test[predictors]\n",
    "y_test = d_test[target]\n",
    "print(\"Train: N = {0}, P(Interview) = {1:.5f}\".format(len(X_train), y_train.mean()))\n",
    "print(\"Test:  N = {0}, P(Interview) = {1:.5f}\".format(len(X_test), y_test.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3559e05206b5f62c4006c5ec2805c1421e8cbf5"
   },
   "source": [
    "How well would a logistic regression separate the interviewed and rejected applicants?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0eef3952e5d37426f5322c2b6a143e8cf1e8d74a"
   },
   "outputs": [],
   "source": [
    "logres = LogisticRegression(solver=\"liblinear\", penalty=\"l2\", fit_intercept=True)\n",
    "logres.fit(X_train, y_train)\n",
    "evaluate_model(y_test, logres.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db87a80d7bf263e3f9630e350f6d1b23a9e0b7c7"
   },
   "source": [
    "That's pretty good But the PARiS system can do an even better job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e1f726ce9bb786be37ba600304ffcdd0a7eb3980"
   },
   "outputs": [],
   "source": [
    "paris = PARiSClassifier(WEIGHTS)\n",
    "paris.fit(X_train, y_train)\n",
    "evaluate_model(y_test, paris.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6d7f165faeba842bd1fa35da0627f0cfc8887c57"
   },
   "source": [
    "Compare other models to PARiS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6f08c0fc88452df5bd0c2a4796a20092b98ed6b6"
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(PARiSClassifier(WEIGHTS))\n",
    "models.append(LogisticRegression(solver=\"liblinear\", penalty=\"l2\", fit_intercept=True))\n",
    "models.append(DecisionTreeClassifier())\n",
    "models.append(KNeighborsClassifier(n_neighbors=3))\n",
    "print(\"{} models\".format(len(models)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "11fe6d9dcafe16236c5bc12dffff40b899155fe2"
   },
   "outputs": [],
   "source": [
    "rdf, cols, clfs = rank_models(models, d_train, y_train, d_test, y_test, predictors, demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "daccfd8543bdde79c4e036e8847fbdfa4e47bcb1"
   },
   "outputs": [],
   "source": [
    "rdf[cols].sort_values(by=\"F1\", ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "faf689db4f23ed4d95717d48721f5cfdac24c38d"
   },
   "source": [
    "## Pilot Dataset\n",
    "\n",
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be297ffd2b75e9acbc41ab052dbe41edb99f0811"
   },
   "outputs": [],
   "source": [
    "pilot = pd.read_csv(\"../input/resumes_pilot.csv\", index_col=0)\n",
    "pilot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "05ec2736d98f21612c2afb787833bdc2a9556ff0"
   },
   "source": [
    "Check the correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d0a66808c8655e5a554d218be5f4e3d496b02d7a"
   },
   "outputs": [],
   "source": [
    "pilot[[target] + demographics].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f464cf6bb5a63f2bca6d2349ad8eb17ace471501"
   },
   "outputs": [],
   "source": [
    "Compare the models on the pilot data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "77dd23d03fa38698150cf6e9629f002b7a0069fb"
   },
   "outputs": [],
   "source": [
    "y_pilot = pilot[target]\n",
    "d_pilot = pilot[predictors + demographics]\n",
    "rdf, cols, clfs = rank_models(models, d_train, y_train, d_pilot, y_pilot, predictors, demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f67bfc2233b03266f0b176079de5a0cd1566b5c3"
   },
   "outputs": [],
   "source": [
    "rdf[cols].sort_values(by=\"F1\", ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b7ab820e3ed5b6493309eea5428552b964375514"
   },
   "source": [
    "Inspect the false negatives produced by PARiS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3eb5b43b236b33fd3fe0a320452139b0aca9750c"
   },
   "outputs": [],
   "source": [
    "from fairness import unvectorize\n",
    "\n",
    "pclf = clfs[0]\n",
    "for i, (yt, pa, x) in enumerate(zip(pilot[target], pclf.predict_proba(pilot[predictors])[:,1], pilot.values)):\n",
    "    if yt == 1 and pa < pclf.threshold:\n",
    "        print(\"Applicant {0}, P(I|X) = {1:.3f}\".format(i, pa))\n",
    "        skills = unvectorize(pilot.columns, x)\n",
    "        print(\"{}\".format(\", \".join(skills)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5401bdeb968cbe3fa2c2e1cc07bac033ab3626a7"
   },
   "source": [
    "**Hypothesis:** Many employees have a history of playing sports. None of these applicants marked as false negative had athletics on their resume. Perhaps the model is biased against this.\n",
    "\n",
    "There are six features related to sports, and all six are positively correlated with getting an interview in our training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "49e06a7147785243fc3d0f9d7942e09cbbccf29e"
   },
   "outputs": [],
   "source": [
    "sports = [\n",
    "    \"Basketball\",\n",
    "    \"Football\",\n",
    "    \"Baseball\",\n",
    "    \"Swimming\",\n",
    "    \"Soccer\",\n",
    "    \"Diving\"\n",
    "]\n",
    "data[[target] + sports].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7eadb9a9d4077da9e7a7c91c22adc92e6036410a"
   },
   "source": [
    "PARiS also has positive weights for alll six sports features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fb0112757fae4feffd4737ec96979c096a27ab3b"
   },
   "outputs": [],
   "source": [
    "sports_idx = [predictors.index(sport) for sport in sports]\n",
    "sports_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53f331abd263e9ca310ce4118c5c9163e2492623"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(WEIGHTS[0][sports_idx], sports)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
